{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7adc72",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2328b02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ikmalkamil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ikmalkamil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ikmalkamil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e8aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Rafael Nadal Joins Roger Federer in Missing U.S. Open\",\n",
    "    \"Rafael Nadal Is Out of the Australian Open\",\n",
    "    \"Biden Announces Virus Measures\",\n",
    "    \"Biden's Virus Plans Meet Reality\",\n",
    "    \"Where Biden's Virus Plan Stands\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9576a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rafael', 'nadal', 'join', 'roger', 'federer', 'missing', 'open'],\n",
       " ['rafael', 'nadal', 'australian', 'open'],\n",
       " ['biden', 'announces', 'virus', 'measure'],\n",
       " ['biden', 'virus', 'plan', 'meet', 'reality'],\n",
       " ['biden', 'virus', 'plan', 'stand']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec54e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6922d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734df683",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd6d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_labels = []\n",
    "\n",
    "for i, doc in enumerate(preprocessed_documents):\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    article_labels.append(dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62157f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topics:\n",
      "                                             Article  Topic\n",
      "0  Rafael Nadal Joins Roger Federer in Missing U....      0\n",
      "1         Rafael Nadal Is Out of the Australian Open      0\n",
      "2                     Biden Announces Virus Measures      1\n",
      "3                   Biden's Virus Plans Meet Reality      1\n",
      "4                    Where Biden's Virus Plan Stands      1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Article\": documents, \"Topic\": article_labels})\n",
    "\n",
    "print(\"Table with Articles and Topics:\")\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc379295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms for Each Topic :\n",
      "Topic 0:\n",
      "- \"nadal\" (weight: 0.131)\n",
      "- \"open\" (weight: 0.131)\n",
      "- \"rafael\" (weight: 0.131)\n",
      "- \"roger\" (weight: 0.079)\n",
      "- \"federer\" (weight: 0.079)\n",
      "- \"join\" (weight: 0.079)\n",
      "- \"missing\" (weight: 0.079)\n",
      "- \"australian\" (weight: 0.079)\n",
      "- \"stand\" (weight: 0.027)\n",
      "- \"biden\" (weight: 0.027)\n",
      "\n",
      "Topic 1:\n",
      "- \"virus\" (weight: 0.166)\n",
      "- \"biden\" (weight: 0.166)\n",
      "- \"plan\" (weight: 0.119)\n",
      "- \"meet\" (weight: 0.071)\n",
      "- \"reality\" (weight: 0.071)\n",
      "- \"announces\" (weight: 0.071)\n",
      "- \"measure\" (weight: 0.071)\n",
      "- \"stand\" (weight: 0.071)\n",
      "- \"australian\" (weight: 0.024)\n",
      "- \"rafael\" (weight: 0.024)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Terms for Each Topic :\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def5df03",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131b6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ikmalkamil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ikmalkamil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ikmalkamil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ec96d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('npr.csv')\n",
    "documents = df['Article'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf127787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['washington', '2016', 'even', 'policy', 'bipartisan', 'politics', 'sense', 'year', 'show', 'little', 'sign', 'ending', 'president', 'obama', 'moved', 'sanction', 'russia', 'alleged', 'interference', 'election', 'concluded', 'republican', 'long', 'called', 'similar', 'severe', 'measure', 'could', 'scarcely', 'bring', 'approve', 'house', 'speaker', 'paul', 'ryan', 'called', 'obama', 'measure', 'appropriate', 'also', 'overdue', 'prime', 'example', 'administration', 'ineffective', 'foreign', 'policy', 'left', 'america', 'weaker', 'eye', 'gop', 'leader', 'sounded', 'much', 'theme', 'urging', 'president', 'obama', 'year', 'take', 'strong', 'action', 'deter', 'russia', 'worldwide', 'aggression', 'including', 'operation', 'wrote', 'devin', 'nunes', 'chairman', 'house', 'intelligence', 'committee', 'week', 'left', 'office', 'president', 'suddenly', 'decided', 'stronger', 'measure', 'indeed', 'appearing', 'cnn', 'frequent', 'obama', 'critic', 'trent', 'frank', 'called', 'much', 'tougher', 'action', 'said', 'three', 'time', 'obama', 'finally', 'found', 'meanwhile', 'fox', 'news', 'various', 'spokesman', 'trump', 'said', 'obama', 'real', 'target', 'russian', 'man', 'poised', 'take', 'white', 'house', 'le', 'three', 'week', 'spoke', 'obama', 'trying', 'tie', 'trump', 'hand', 'box', 'meaning', 'would', 'forced', 'either', 'keep', 'sanction', 'odds', 'republican', 'want', 'tougher', 'still', 'moscow', 'throughout', '2016', 'trump', 'repeatedly', 'called', 'sanction', 'closer', 'tie', 'russia', 'including', 'cooperation', 'fight', 'isi', 'russia', 'battled', 'isi', 'syria', 'behalf', 'country', 'embattled', 'dictator', 'bashar', 'assad', 'bombing', 'besieged', 'city', 'aleppo', 'fell', 'assad', 'force', 'week', 'campaign', 'trump', 'even', 'urged', 'russia', 'find', 'missing', 'email', 'private', 'server', 'opponent', 'hillary', 'clinton', 'exchanged', 'public', 'encomium', 'russian', 'president', 'vladimir', 'putin', 'several', 'occasion', 'added', 'doubt', 'current', 'level', 'support', 'nato', 'putin', 'longtime', 'nemesis', 'also', 'suggestion', 'trump', 'extensive', 'business', 'dealing', 'various', 'russian', 'reason', 'refuse', 'release', 'tax', 'return', 'issue', 'disquieting', 'republican', 'many', 'month', 'sen', 'john', 'mccain', 'lindsay', 'graham', 'prominent', 'senior', 'member', 'armed', 'service', 'committee', 'accepted', 'assessment', '17', 'intelligence', 'agency', 'regarding', 'role', 'russia', 'hacking', 'various', 'democratic', 'committee', 'last', 'year', 'includes', 'fbi', 'cia', 'consensus', 'russian', 'goal', 'discredit', 'american', 'democracy', 'defeat', 'clinton', 'elect', 'trump', 'say', 'great', 'majority', 'senate', 'colleague', 'agree', 'mccain', 'slated', 'armed', 'service', 'hearing', 'cyberthreats', 'politicizing', 'russian', 'action', 'idea', 'helped', 'trump', 'win', 'also', 'made', 'issue', 'difficult', 'republican', 'leader', 'allowed', 'trump', 'supporter', 'push', 'back', 'intelligence', 'agency', 'say', 'entire', 'issue', 'designed', 'undermine', 'trump', 'legitimacy', 'senate', 'majority', 'leader', 'mitch', 'mcconnell', 'far', 'resisted', 'call', 'select', 'committee', 'look', 'russian', 'interference', '2016', 'campaign', 'said', 'enough', 'richard', 'burr', 'look', 'chairman', 'senate', 'intelligence', 'committee', 'typically', 'republican', 'leader', 'spokesman', 'say', 'evidence', 'actual', 'voting', 'tallying', '8', 'compromised', 'true', 'also', 'red', 'herring', 'interference', 'function', 'alleged', 'focus', 'intelligence', 'agency', 'concern', 'part', 'trump', 'shown', 'little', 'interest', 'delving', 'happened', 'cast', 'doubt', 'intelligence', 'report', 'date', 'suggested', 'one', 'really', 'know', 'also', 'suggested', 'computer', 'make', 'difficult', 'know', 'using', 'week', 'trump', 'said', 'time', 'get', 'life', 'important', 'however', 'week', 'end', 'agree', 'intelligence', 'briefing', 'subject', 'next', 'week', 'wanted', 'daily', 'intelligence', 'briefing', 'available', 'recent', 'week', 'preferring', 'given', 'men', 'chosen', 'vice', 'president', 'mike', 'penny', 'national', 'security', 'adviser', 'mike', 'flynn', 'trump', 'taking', 'occasionally', 'irony', 'controversy', 'arising', 'eleventh', 'hour', 'obama', 'presidency', 'scarcely', 'overstated', 'defines', 'dilemma', 'facing', 'outgoing', 'president', 'incoming', 'party', 'control', 'obama', 'appears', 'reluctant', 'retaliate', 'russian', 'hacking', 'election', 'fear', 'seeming', 'interfere', 'election', 'republican', 'meanwhile', 'year', 'called', 'greater', 'confrontation', 'russian', 'obama', 'usually', 'resisting', 'obama', 'join', 'nato', 'punishing', 'russian', 'economic', 'sanction', 'annexation', 'crimea', 'sanction', 'may', 'painful', 'coming', 'alongside', 'falling', 'price', 'oil', 'commodity', 'keep', 'russian', 'economy', 'afloat', 'occasion', 'despite', 'russian', 'provocation', 'surrogate', 'syria', 'elsewhere', 'obama', 'make', 'overt', 'move', 'force', 'russia', 'hand', 'includes', 'occasion', 'russia', 'believed', 'hacking', 'critical', 'computer', 'system', 'neighboring', 'ukraine', 'estonia', 'poland', 'week', 'following', 'chorus', 'confirmation', 'intelligence', 'community', 'regarding', 'russian', 'role', 'computer', 'hacking', 'political', 'campaign', 'obama', 'acted', 'imposed', 'set', 'mostly', 'diplomatic', 'action', 'sanctioning', 'russian', 'official', 'closing', 'two', 'diplomatic', 'compound', 'expelling', '35', 'russian', 'diplomat', 'may', 'damaging', 'measure', 'taken', 'covertly', 'russophobes', 'washington', 'held', 'hope', 'visible', 'portion', 'program', 'scarcely', 'amounted', 'major', 'retribution', 'putin', 'saw', 'fit', 'diminish', 'obama', 'sanction', 'declining', 'respond', 'although', 'government', 'steadfastly', 'denied', 'interference', 'election', 'putin', 'rejected', 'foreign', 'minister', 'recommended', 'package', 'response', 'even', 'sent', 'invitation', 'diplomat', 'send', 'child', 'holiday', 'party', 'moscow', 'allowed', 'putin', 'appear', 'moment', 'bigger', 'man', 'even', 'spurned', 'obama', 'kept', 'looked', 'like', 'public', 'bromance', 'trump', 'tweeted', 'great', 'move', 'delay', 'putin', 'always', 'knew', 'smart', 'moment', 'may', 'seem', 'overall', 'russia', 'question', 'amount', 'first', 'crisis', 'facing', 'trump', 'presidency', 'whether', 'forced', 'campaign', 'interference', 'issue', 'trump', 'must', 'grasp', 'nettle', 'relationship', 'mitt', 'romney', 'called', 'greatest', 'threat', 'security', 'world', 'sure', 'trump', 'need', 'dispel', 'doubt', 'ability', 'stand', 'putin', 'bullied', 'cajoled', 'way', 'center', 'stage', 'recent', 'world', 'affair', 'trump', 'also', 'seems', 'determined', 'turn', 'page', 'past', 'commitment', 'free', 'trade', 'philosophy', 'funding', 'nato', 'united', 'nation', 'twitter', 'account', 'guide', 'trump', 'show', 'little', 'concern', 'conundrum', 'others', 'perceive', 'facing', 'trump', 'shown', 'determined', 'play', 'rule', 'year', 'ago', 'many', 'confident', 'would', 'work', 'world', 'presidential', 'politics', 'find', 'whether', 'work', 'oval', 'office']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum()] \n",
    "    tokens = [token for token in tokens if token not in stop_words] \n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens] \n",
    "    return tokens \n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents] \n",
    "print(preprocessed_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70a31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(preprocessed_documents)\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "836d4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e64e92c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic:\n",
      "                                                 Article  Topic\n",
      "0      In the Washington of 2016, even when the polic...      0\n",
      "1        Donald Trump has used Twitter  —   his prefe...      4\n",
      "2        Donald Trump is unabashedly praising Russian...      0\n",
      "3      Updated at 2:50 p. m. ET, Russian President Vl...      4\n",
      "4      From photography, illustration and video, to d...      2\n",
      "...                                                  ...    ...\n",
      "11987  The number of law enforcement officers shot an...      1\n",
      "11988    Trump is busy these days with victory tours,...      0\n",
      "11989  It’s always interesting for the Goats and Soda...      3\n",
      "11990  The election of Donald Trump was a surprise to...      0\n",
      "11991  Voters in the English city of Sunderland did s...      4\n",
      "\n",
      "[11992 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_labels = []\n",
    "\n",
    "for i, doc in enumerate(preprocessed_documents):\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    article_labels.append(dominant_topic)\n",
    "    \n",
    "df_result = pd.DataFrame({\"Article\": documents, \"Topic\": article_labels})\n",
    "\n",
    "print(\"Table with Articles and Topic:\")\n",
    "print(df_result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77fea74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for Topic #0:\n",
      "['trump', 'clinton', 'state', 'president', 'republican', 'campaign', 'election', 'vote', 'obama', 'voter']\n",
      "\n",
      "Top terms for Topic #1:\n",
      "['police', 'law', 'court', 'state', 'report', 'case', 'department', 'told', 'officer', 'official']\n",
      "\n",
      "Top terms for Topic #2:\n",
      "['know', 'thing', 'think', 'life', 'really', 'story', 'back', 'day', 'show', 'go']\n",
      "\n",
      "Top terms for Topic #3:\n",
      "['health', 'school', 'study', 'child', 'student', 'percent', 'university', 'care', 'program', 'patient']\n",
      "\n",
      "Top terms for Topic #4:\n",
      "['country', 'war', 'government', 'world', 'president', 'china', 'american', 'woman', 'attack', 'group']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id in range(lda_model.num_topics):\n",
    "    print(f\"Top terms for Topic #{topic_id}:\")\n",
    "    top_terms = lda_model.show_topic(topic_id, topn=10)\n",
    "    print([term[0] for term in top_terms])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "305b96dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms for Each Topic:\n",
      "Topic 0:\n",
      "- \"trump\" (weight: 0.028)\n",
      "- \"clinton\" (weight: 0.011)\n",
      "- \"state\" (weight: 0.010)\n",
      "- \"president\" (weight: 0.009)\n",
      "- \"republican\" (weight: 0.008)\n",
      "- \"campaign\" (weight: 0.007)\n",
      "- \"election\" (weight: 0.006)\n",
      "- \"vote\" (weight: 0.005)\n",
      "- \"obama\" (weight: 0.005)\n",
      "- \"voter\" (weight: 0.005)\n",
      "\n",
      "Topic 1:\n",
      "- \"police\" (weight: 0.008)\n",
      "- \"law\" (weight: 0.007)\n",
      "- \"court\" (weight: 0.006)\n",
      "- \"state\" (weight: 0.006)\n",
      "- \"report\" (weight: 0.006)\n",
      "- \"case\" (weight: 0.005)\n",
      "- \"department\" (weight: 0.005)\n",
      "- \"told\" (weight: 0.004)\n",
      "- \"officer\" (weight: 0.004)\n",
      "- \"official\" (weight: 0.004)\n",
      "\n",
      "Topic 2:\n",
      "- \"know\" (weight: 0.005)\n",
      "- \"thing\" (weight: 0.005)\n",
      "- \"think\" (weight: 0.005)\n",
      "- \"life\" (weight: 0.004)\n",
      "- \"really\" (weight: 0.004)\n",
      "- \"story\" (weight: 0.003)\n",
      "- \"back\" (weight: 0.003)\n",
      "- \"day\" (weight: 0.003)\n",
      "- \"show\" (weight: 0.003)\n",
      "- \"go\" (weight: 0.003)\n",
      "\n",
      "Topic 3:\n",
      "- \"health\" (weight: 0.007)\n",
      "- \"school\" (weight: 0.007)\n",
      "- \"study\" (weight: 0.006)\n",
      "- \"child\" (weight: 0.005)\n",
      "- \"student\" (weight: 0.005)\n",
      "- \"percent\" (weight: 0.005)\n",
      "- \"university\" (weight: 0.004)\n",
      "- \"care\" (weight: 0.004)\n",
      "- \"program\" (weight: 0.004)\n",
      "- \"patient\" (weight: 0.003)\n",
      "\n",
      "Topic 4:\n",
      "- \"country\" (weight: 0.010)\n",
      "- \"war\" (weight: 0.006)\n",
      "- \"government\" (weight: 0.005)\n",
      "- \"world\" (weight: 0.005)\n",
      "- \"president\" (weight: 0.005)\n",
      "- \"china\" (weight: 0.004)\n",
      "- \"american\" (weight: 0.004)\n",
      "- \"woman\" (weight: 0.004)\n",
      "- \"attack\" (weight: 0.004)\n",
      "- \"group\" (weight: 0.004)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Terms for Each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6ad77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
